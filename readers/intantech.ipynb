{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ad2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from .utils import convert_to_number\n",
    "\n",
    "\n",
    "AP_GAIN = 80  # For NP 2.0 probes; APGain = 80 for all AP (LF is computed from AP)\n",
    "\n",
    "# Imax values for different probe types - see metaguides (http://billkarsh.github.io/IntanTECH/#metadata-guides)\n",
    "IMAX = {'neuropixels 1.0 - 3A': 512,\n",
    "        'neuropixels 1.0 - 3B': 512,\n",
    "        'neuropixels 2.0 - SS': 8192,\n",
    "        'neuropixels 2.0 - MS': 8192}\n",
    "\n",
    "\n",
    "class IntanTECH:\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        '''\n",
    "        create neuropixels reader from 'root name' - e.g. the recording:\n",
    "            /data/rec_1/npx_g0_t0.imec.ap.meta\n",
    "            /data/rec_1/npx_g0_t0.imec.ap.bin\n",
    "            /data/rec_1/npx_g0_t0.imec.lf.meta\n",
    "            /data/rec_1/npx_g0_t0.imec.lf.bin\n",
    "        would have a 'root name' of:\n",
    "            /data/rec_1/npx_g0_t0.imec\n",
    "        only a single recording is read/loaded via the root\n",
    "        name & associated meta - no interpretation of g0_t0.imec, etc is\n",
    "        performed at this layer.\n",
    "        '''\n",
    "        self._apmeta, self._ap_timeseries = None, None\n",
    "        self._lfmeta, self._lf_timeseries = None, None\n",
    "\n",
    "        self.root_dir = pathlib.Path(root_dir)\n",
    "\n",
    "        try:\n",
    "            meta_filepath = next(pathlib.Path(root_dir).glob('*.ap.meta'))\n",
    "        except StopIteration:\n",
    "            raise FileNotFoundError(f'No IntanTECH file (.ap.meta) found at: {root_dir}')\n",
    "\n",
    "        self.root_name = meta_filepath.name.replace('.ap.meta', '')\n",
    "\n",
    "    @property\n",
    "    def apmeta(self):\n",
    "        if self._apmeta is None:\n",
    "            self._apmeta = IntanTECHMeta(self.root_dir / (self.root_name + '.ap.meta'))\n",
    "        return self._apmeta\n",
    "\n",
    "    @property\n",
    "    def ap_timeseries(self):\n",
    "        \"\"\"\n",
    "        AP data: (sample x channel)\n",
    "        Data are stored as np.memmap with dtype: int16\n",
    "        - to convert to microvolts, multiply with self.get_channel_bit_volts('ap')\n",
    "        \"\"\"\n",
    "        if self._ap_timeseries is None:\n",
    "            self._ap_timeseries = self._read_bin(self.root_dir / (self.root_name + '.ap.bin'))\n",
    "        return self._ap_timeseries\n",
    "\n",
    "    @property\n",
    "    def lfmeta(self):\n",
    "        if self._lfmeta is None:\n",
    "            self._lfmeta = IntanTECHMeta(self.root_dir / (self.root_name + '.lf.meta'))\n",
    "        return self._lfmeta\n",
    "\n",
    "    @property\n",
    "    def lf_timeseries(self):\n",
    "        \"\"\"\n",
    "        LFP data: (sample x channel)\n",
    "        Data are stored as np.memmap with dtype: int16\n",
    "        - to convert to microvolts, multiply with self.get_channel_bit_volts('lf')\n",
    "        \"\"\"\n",
    "        if self._lf_timeseries is None:\n",
    "            self._lf_timeseries = self._read_bin(self.root_dir / (self.root_name + '.lf.bin'))\n",
    "        return self._lf_timeseries\n",
    "\n",
    "    def get_channel_bit_volts(self, band='ap'):\n",
    "        \"\"\"\n",
    "        Extract the recorded AP and LF channels' int16 to microvolts - no Sync (SY) channels\n",
    "        Following the steps specified in: https://billkarsh.github.io/IntanTECH/Support/IntanTECH_Datafile_Tools.zip\n",
    "                dataVolts = dataInt * Vmax / Imax / gain\n",
    "        \"\"\"\n",
    "        vmax = float(self.apmeta.meta['imAiRangeMax'])\n",
    "\n",
    "        if band == 'ap':\n",
    "            imax = IMAX[self.apmeta.probe_model]\n",
    "            imroTbl_data = self.apmeta.imroTbl['data']\n",
    "            imroTbl_idx = 3\n",
    "            chn_ind = self.apmeta.get_recording_channels_indices(exclude_sync=True)\n",
    "\n",
    "        elif band == 'lf':\n",
    "            imax = IMAX[self.lfmeta.probe_model]\n",
    "            imroTbl_data = self.lfmeta.imroTbl['data']\n",
    "            imroTbl_idx = 4\n",
    "            chn_ind = self.lfmeta.get_recording_channels_indices(exclude_sync=True)\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported band: {band} - Must be \"ap\" or \"lf\"')\n",
    "\n",
    "        # extract channels' gains\n",
    "        if 'imDatPrb_dock' in self.apmeta.meta:\n",
    "            # NP 2.0; APGain = 80 for all AP (LF is computed from AP)\n",
    "            chn_gains = [AP_GAIN] * len(imroTbl_data)\n",
    "        else:\n",
    "            # 3A, 3B1, 3B2 (NP 1.0)\n",
    "            chn_gains = [c[imroTbl_idx] for c in imroTbl_data]\n",
    "\n",
    "        chn_gains = np.array(chn_gains)[chn_ind]\n",
    "\n",
    "        return vmax / imax / chn_gains * 1e6  # convert to uV as well\n",
    "\n",
    "    def _read_bin(self, fname):\n",
    "        nchan = self.apmeta.meta['nSavedChans']\n",
    "        dtype = np.dtype((np.int16, nchan))\n",
    "        return np.memmap(fname, dtype, 'r')\n",
    "\n",
    "    def extract_spike_waveforms(self, spikes, channel_ind, n_wf=500, wf_win=(-32, 32)):\n",
    "        \"\"\"\n",
    "        :param spikes: spike times (in second) to extract waveforms\n",
    "        :param channel_ind: channel indices (of shankmap) to extract the waveforms from\n",
    "        :param n_wf: number of spikes per unit to extract the waveforms\n",
    "        :param wf_win: number of sample pre and post a spike\n",
    "        :return: waveforms (in uV) - shape: (sample x channel x spike)\n",
    "        \"\"\"\n",
    "        channel_bit_volts = self.get_channel_bit_volts('ap')[channel_ind]\n",
    "\n",
    "        data = self.ap_timeseries\n",
    "\n",
    "        spikes = np.round(spikes * self.apmeta.meta['imSampRate']).astype(int)  # convert to sample\n",
    "        # ignore spikes at the beginning or end of raw data\n",
    "        spikes = spikes[np.logical_and(spikes > -wf_win[0],\n",
    "                                       spikes < data.shape[0] - wf_win[-1])]\n",
    "\n",
    "        np.random.shuffle(spikes)\n",
    "        spikes = spikes[:n_wf]\n",
    "        if len(spikes) > 0:\n",
    "            # waveform at each spike: (sample x channel x spike)\n",
    "            spike_wfs = np.dstack([data[int(spk + wf_win[0]):int(spk + wf_win[-1]),\n",
    "                                   channel_ind] * channel_bit_volts\n",
    "                                   for spk in spikes])\n",
    "            return spike_wfs\n",
    "        else:  # if no spike found, return NaN of size (sample x channel x 1)\n",
    "            return np.full((len(range(*wf_win)), len(channel_ind), 1), np.nan)\n",
    "\n",
    "\n",
    "class IntanTECHMeta:\n",
    "\n",
    "    def __init__(self, meta_filepath):\n",
    "        \"\"\"\n",
    "        Some good processing references:\n",
    "            https://billkarsh.github.io/IntanTECH/Support/IntanTECH_Datafile_Tools.zip\n",
    "            https://github.com/jenniferColonell/Neuropixels_evaluation_tools/blob/master/SGLXMetaToCoords.m\n",
    "        \"\"\"\n",
    "\n",
    "        self.fname = meta_filepath\n",
    "        self.meta = _read_meta(meta_filepath)\n",
    "\n",
    "        # Infer npx probe model (e.g. 1.0 (3A, 3B) or 2.0)\n",
    "        probe_model = self.meta.get('imDatPrb_type', 1)\n",
    "        if probe_model <= 1:\n",
    "            if 'typeEnabled' in self.meta:\n",
    "                self.probe_model = 'neuropixels 1.0 - 3A'\n",
    "            elif 'typeImEnabled' in self.meta:\n",
    "                self.probe_model = 'neuropixels 1.0 - 3B'\n",
    "        elif probe_model == 21:\n",
    "            self.probe_model = 'neuropixels 2.0 - SS'\n",
    "        elif probe_model == 24:\n",
    "            self.probe_model = 'neuropixels 2.0 - MS'\n",
    "        else:\n",
    "            self.probe_model = str(probe_model)\n",
    "\n",
    "        # Get recording time\n",
    "        self.recording_time = datetime.strptime(self.meta.get('fileCreateTime_original',\n",
    "                                                              self.meta['fileCreateTime']),\n",
    "                                                '%Y-%m-%dT%H:%M:%S')\n",
    "        self.recording_duration = self.meta.get('fileTimeSecs')\n",
    "\n",
    "        # Get probe serial number - 'imProbeSN' for 3A and 'imDatPrb_sn' for 3B\n",
    "        try:\n",
    "            self.probe_SN = self.meta.get('imProbeSN', self.meta.get('imDatPrb_sn'))\n",
    "        except KeyError:\n",
    "            raise KeyError('Probe Serial Number not found in'\n",
    "                           ' either \"imProbeSN\" or \"imDatPrb_sn\"')\n",
    "\n",
    "        self.chanmap = (self._parse_chanmap(self.meta['~snsChanMap'])\n",
    "                        if '~snsChanMap' in self.meta else None)\n",
    "        self.shankmap = (self._parse_shankmap(self.meta['~snsShankMap'])\n",
    "                         if '~snsShankMap' in self.meta else None)\n",
    "        self.imroTbl = (self._parse_imrotbl(self.meta['~imroTbl'])\n",
    "                        if '~imroTbl' in self.meta else None)\n",
    "\n",
    "        # Channels being recorded, exclude Sync channels - basically a 1-1 mapping to shankmap\n",
    "        self.recording_channels = np.arange(len(self.imroTbl['data']))[\n",
    "            self.get_recording_channels_indices(exclude_sync=True)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_chanmap(raw):\n",
    "        '''\n",
    "        https://github.com/billkarsh/IntanTECH/blob/master/Markdown/UserManual.md#channel-map\n",
    "        Parse channel map header structure. Converts:\n",
    "            '(x,y,z)(c0,x:y)...(cI,x:y),(sy0;x:y)'\n",
    "        e.g:\n",
    "            '(384,384,1)(AP0;0:0)...(AP383;383:383)(SY0;768:768)'\n",
    "        into dict of form:\n",
    "            {'shape': [x,y,z], 'c0': [x,y], ... }\n",
    "        '''\n",
    "\n",
    "        res = {}\n",
    "        for u in (i.rstrip(')').split(';') for i in raw.split('(') if i != ''):\n",
    "            if (len(u)) == 1:\n",
    "                res['shape'] = u[0].split(',')\n",
    "            else:\n",
    "                res[u[0]] = u[1].split(':')\n",
    "\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_shankmap(raw):\n",
    "        \"\"\"\n",
    "        The shankmap contains details on the shank info\n",
    "            for each electrode sites of the sites being recorded only\n",
    "        https://github.com/billkarsh/IntanTECH/blob/master/Markdown/UserManual.md#shank-map\n",
    "        Parse shank map header structure. Converts:\n",
    "            '(x,y,z)(a:b:c:d)...(a:b:c:d)'\n",
    "        e.g:\n",
    "            '(1,2,480)(0:0:192:1)...(0:1:191:1)'\n",
    "        into dict of form:\n",
    "            {'shape': [x,y,z], 'data': [[a,b,c,d],...]}\n",
    "        \"\"\"\n",
    "        res = {'shape': None, 'data': []}\n",
    "\n",
    "        for u in (i.rstrip(')') for i in raw.split('(') if i != ''):\n",
    "            if ',' in u:\n",
    "                res['shape'] = [int(d) for d in u.split(',')]\n",
    "            else:\n",
    "                res['data'].append([int(d) for d in u.split(':')])\n",
    "\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_imrotbl(raw):\n",
    "        \"\"\"\n",
    "        The imro table contains info for all electrode sites (no sync)\n",
    "            for a particular electrode configuration (all 384 sites)\n",
    "        Note: not all of these 384 sites are necessarily recorded\n",
    "        https://github.com/billkarsh/IntanTECH/blob/master/Markdown/UserManual.md#imro-per-channel-settings\n",
    "        Parse imro tbl structure. Converts:\n",
    "            '(X,Y,Z)(A B C D E)...(A B C D E)'\n",
    "        e.g.:\n",
    "            '(641251209,3,384)(0 1 0 500 250)...(383 0 0 500 250)'\n",
    "        into dict of form:\n",
    "            {'shape': (x,y,z), 'data': []}\n",
    "        \"\"\"\n",
    "        res = {'shape': None, 'data': []}\n",
    "\n",
    "        for u in (i.rstrip(')') for i in raw.split('(') if i != ''):\n",
    "            if ',' in u:\n",
    "                res['shape'] = [int(d) for d in u.split(',')]\n",
    "            else:\n",
    "                res['data'].append([int(d) for d in u.split(' ')])\n",
    "\n",
    "        return res\n",
    "\n",
    "    def get_recording_channels_indices(self, exclude_sync=False):\n",
    "        \"\"\"\n",
    "        The indices of recorded channels (in chanmap)\n",
    "         with respect to the channels listed in the imro table\n",
    "        \"\"\"\n",
    "        recorded_chns_ind = [int(v[0]) for k, v in self.chanmap.items()\n",
    "                             if k != 'shape'\n",
    "                             and (not k.startswith('SY') if exclude_sync else True)]\n",
    "        orig_chns_ind = self.get_original_chans()\n",
    "        _, _, chns_ind = np.intersect1d(orig_chns_ind, recorded_chns_ind,\n",
    "                                        return_indices=True)\n",
    "        return chns_ind\n",
    "\n",
    "    def get_original_chans(self):\n",
    "        \"\"\"\n",
    "        Because you can selectively save channels, the\n",
    "        ith channel in the file isn't necessarily the ith acquired channel.\n",
    "        Use this function to convert from ith stored to original index.\n",
    "        Credit to https://billkarsh.github.io/IntanTECH/Support/IntanTECH_Datafile_Tools.zip\n",
    "            OriginalChans() function\n",
    "        \"\"\"\n",
    "        if self.meta['snsSaveChanSubset'] == 'all':\n",
    "            # output = int32, 0 to nSavedChans - 1\n",
    "            channels = np.arange(0, int(self.meta['nSavedChans']))\n",
    "        else:\n",
    "            # parse the channel list self.meta['snsSaveChanSubset']\n",
    "            channels = np.arange(0)  # empty array\n",
    "            for channel_range in self.meta['snsSaveChanSubset'].split(','):\n",
    "                # a block of contiguous channels specified as chan or chan1:chan2 inclusive\n",
    "                ix = [int(r) for r in channel_range.split(':')]\n",
    "                assert len(ix) in (1, 2), f\"Invalid channel range spec '{channel_range}'\"\n",
    "                channels = np.append(channels, np.r_[ix[0]:ix[-1] + 1])\n",
    "        return channels\n",
    "\n",
    "\n",
    "# ============= HELPER FUNCTIONS =============\n",
    "\n",
    "def _read_meta(meta_filepath):\n",
    "    \"\"\"\n",
    "    Read metadata in 'k = v' format.\n",
    "    The fields '~snsChanMap' and '~snsShankMap' are further parsed into\n",
    "    'snsChanMap' and 'snsShankMap' dictionaries via calls to\n",
    "    IntanTECH._parse_chanmap and IntanTECH._parse_shankmap.\n",
    "    \"\"\"\n",
    "\n",
    "    res = {}\n",
    "    with open(meta_filepath) as f:\n",
    "        for l in (l.rstrip() for l in f):\n",
    "            if '=' in l:\n",
    "                try:\n",
    "                    k, v = l.split('=')\n",
    "                    v = convert_to_number(v)\n",
    "                    res[k] = v\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
